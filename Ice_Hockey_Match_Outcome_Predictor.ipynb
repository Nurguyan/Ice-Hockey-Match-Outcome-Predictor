{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ice-Hockey-Match-Outcome-Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nurguyan/Ice-Hockey-Match-Outcome-Predictor/blob/main/Ice_Hockey_Match_Outcome_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my16SM3edrwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8205ad-b2cf-4a64-e5f8-be7114511aea"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Nurguyan/Ice-Hockey-Match-Outcome-Predictor/main/data/data.csv'\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "print(df[:2])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         Date Location Team   GF   GA  ...    Sh%    Sv%    PP%    PK%  Class\n",
            "0  07/09/2018     Home  LON  247  161  ...  36.85  29.08  26.17  82.06   Loss\n",
            "1  07/09/2018     Away  TER  223  144  ...  40.69  32.31  32.44  84.10    Win\n",
            "\n",
            "[2 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPLYrmEcFJGU",
        "outputId": "6d473396-6039-45be-9d5b-468d2b7776c1"
      },
      "source": [
        "#we assume that outcome of the match do not depend on its date\n",
        "df = df.drop(['Date'], axis=1)\n",
        "\n",
        "#convert categorical data into integers\n",
        "df = pd.get_dummies(df, columns=['Team'])\n",
        "df['Location'] = (df['Location'] == 'Home').astype(int)\n",
        "df['Class'] = (df['Class'] == 'Win').astype(int)\n",
        "\n",
        "print(df[:5])\n",
        "df.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Location   GF   GA   GF%  ...  Team_STJ  Team_TER  Team_VAL  Team_WIS\n",
            "0         1  247  161  5.15  ...         0         0         0         0\n",
            "1         0  223  144  4.65  ...         0         1         0         0\n",
            "2         1  202  211  4.21  ...         0         0         0         0\n",
            "3         0  200  207  4.17  ...         0         0         0         0\n",
            "4         0  207  151  4.31  ...         1         0         0         0\n",
            "\n",
            "[5 rows x 21 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1008 entries, 0 to 1007\n",
            "Data columns (total 21 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Location  1008 non-null   int64  \n",
            " 1   GF        1008 non-null   int64  \n",
            " 2   GA        1008 non-null   int64  \n",
            " 3   GF%       1008 non-null   float64\n",
            " 4   GA%       1008 non-null   float64\n",
            " 5   Sh%       1008 non-null   float64\n",
            " 6   Sv%       1008 non-null   float64\n",
            " 7   PP%       1008 non-null   float64\n",
            " 8   PK%       1008 non-null   float64\n",
            " 9   Class     1008 non-null   int64  \n",
            " 10  Team_CDS  1008 non-null   uint8  \n",
            " 11  Team_CHA  1008 non-null   uint8  \n",
            " 12  Team_GAT  1008 non-null   uint8  \n",
            " 13  Team_GRA  1008 non-null   uint8  \n",
            " 14  Team_LON  1008 non-null   uint8  \n",
            " 15  Team_MTE  1008 non-null   uint8  \n",
            " 16  Team_PRI  1008 non-null   uint8  \n",
            " 17  Team_STJ  1008 non-null   uint8  \n",
            " 18  Team_TER  1008 non-null   uint8  \n",
            " 19  Team_VAL  1008 non-null   uint8  \n",
            " 20  Team_WIS  1008 non-null   uint8  \n",
            "dtypes: float64(6), int64(4), uint8(11)\n",
            "memory usage: 89.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_UgQmeu3qkk",
        "outputId": "82e98307-fcea-41ad-8aaf-f0ae6cd1f197"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_features = df.drop(['Class'], axis=1)\n",
        "Y_feature = df['Class']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_features, Y_feature, test_size=0.20, random_state=4)\n",
        "print(\"Using %d samples for training and %d for validation\" % (len(x_train), len(x_test)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 806 samples for training and 202 for validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdBYDxJAJC2w",
        "outputId": "68d559db-88e5-40c7-b9d4-dc1ddb4b3c55"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#normalize features\n",
        "scaler = MinMaxScaler()\n",
        "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns = x_train.columns)\n",
        "x_test = pd.DataFrame(scaler.transform(x_test), columns = x_test.columns)\n",
        "\n",
        "print(x_train[:5])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Location        GF        GA  ...  Team_TER  Team_VAL  Team_WIS\n",
            "0       1.0  0.038760  1.000000  ...       0.0       0.0       1.0\n",
            "1       1.0  0.139535  0.713415  ...       0.0       0.0       0.0\n",
            "2       1.0  0.542636  0.164634  ...       1.0       0.0       0.0\n",
            "3       1.0  0.937984  0.000000  ...       0.0       0.0       0.0\n",
            "4       1.0  0.139535  0.713415  ...       0.0       0.0       0.0\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzrRxbYhLkgy"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Eh2kLYLyl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6058e3-6b76-43bf-99af-38246bb3f1de"
      },
      "source": [
        "history = model.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), epochs=300, verbose=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.7023 - accuracy: 0.4702 - val_loss: 0.6906 - val_accuracy: 0.5693\n",
            "Epoch 2/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5955 - val_loss: 0.6776 - val_accuracy: 0.5941\n",
            "Epoch 3/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.6154 - val_loss: 0.6691 - val_accuracy: 0.5891\n",
            "Epoch 4/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.6191 - val_loss: 0.6615 - val_accuracy: 0.5941\n",
            "Epoch 5/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.6377 - val_loss: 0.6558 - val_accuracy: 0.6188\n",
            "Epoch 6/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6439 - val_loss: 0.6510 - val_accuracy: 0.6188\n",
            "Epoch 7/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6452 - val_loss: 0.6472 - val_accuracy: 0.6337\n",
            "Epoch 8/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6514 - val_loss: 0.6432 - val_accuracy: 0.6337\n",
            "Epoch 9/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6476 - val_loss: 0.6411 - val_accuracy: 0.6337\n",
            "Epoch 10/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6403 - accuracy: 0.6576 - val_loss: 0.6378 - val_accuracy: 0.6337\n",
            "Epoch 11/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6389 - accuracy: 0.6476 - val_loss: 0.6353 - val_accuracy: 0.6287\n",
            "Epoch 12/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.6514 - val_loss: 0.6340 - val_accuracy: 0.6287\n",
            "Epoch 13/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6514 - val_loss: 0.6329 - val_accuracy: 0.6287\n",
            "Epoch 14/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6514 - val_loss: 0.6321 - val_accuracy: 0.6287\n",
            "Epoch 15/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6514 - val_loss: 0.6320 - val_accuracy: 0.6287\n",
            "Epoch 16/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6464 - val_loss: 0.6309 - val_accuracy: 0.6287\n",
            "Epoch 17/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6514 - val_loss: 0.6308 - val_accuracy: 0.6287\n",
            "Epoch 18/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.6514 - val_loss: 0.6307 - val_accuracy: 0.6287\n",
            "Epoch 19/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.6514 - val_loss: 0.6306 - val_accuracy: 0.6287\n",
            "Epoch 20/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.6514 - val_loss: 0.6297 - val_accuracy: 0.6287\n",
            "Epoch 21/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6514 - val_loss: 0.6305 - val_accuracy: 0.6287\n",
            "Epoch 22/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.6514 - val_loss: 0.6303 - val_accuracy: 0.6287\n",
            "Epoch 23/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.6514 - val_loss: 0.6293 - val_accuracy: 0.6287\n",
            "Epoch 24/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.6514 - val_loss: 0.6293 - val_accuracy: 0.6287\n",
            "Epoch 25/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.6514 - val_loss: 0.6298 - val_accuracy: 0.6287\n",
            "Epoch 26/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.6514 - val_loss: 0.6294 - val_accuracy: 0.6287\n",
            "Epoch 27/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.6514 - val_loss: 0.6299 - val_accuracy: 0.6287\n",
            "Epoch 28/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6514 - val_loss: 0.6289 - val_accuracy: 0.6287\n",
            "Epoch 29/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6514 - val_loss: 0.6290 - val_accuracy: 0.6287\n",
            "Epoch 30/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6321 - accuracy: 0.6514 - val_loss: 0.6288 - val_accuracy: 0.6287\n",
            "Epoch 31/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.6514 - val_loss: 0.6293 - val_accuracy: 0.6287\n",
            "Epoch 32/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.6514 - val_loss: 0.6292 - val_accuracy: 0.6287\n",
            "Epoch 33/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.6514 - val_loss: 0.6293 - val_accuracy: 0.6287\n",
            "Epoch 34/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6514 - val_loss: 0.6289 - val_accuracy: 0.6287\n",
            "Epoch 35/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6514 - val_loss: 0.6293 - val_accuracy: 0.6287\n",
            "Epoch 36/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6321 - accuracy: 0.6514 - val_loss: 0.6294 - val_accuracy: 0.6287\n",
            "Epoch 37/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6514 - val_loss: 0.6290 - val_accuracy: 0.6287\n",
            "Epoch 38/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6514 - val_loss: 0.6288 - val_accuracy: 0.6287\n",
            "Epoch 39/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6514 - val_loss: 0.6294 - val_accuracy: 0.6287\n",
            "Epoch 40/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6514 - val_loss: 0.6289 - val_accuracy: 0.6287\n",
            "Epoch 41/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6514 - val_loss: 0.6290 - val_accuracy: 0.6287\n",
            "Epoch 42/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6514 - val_loss: 0.6290 - val_accuracy: 0.6287\n",
            "Epoch 43/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6514 - val_loss: 0.6292 - val_accuracy: 0.6287\n",
            "Epoch 44/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.6514 - val_loss: 0.6287 - val_accuracy: 0.6287\n",
            "Epoch 45/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6489 - val_loss: 0.6281 - val_accuracy: 0.6287\n",
            "Epoch 46/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.6514 - val_loss: 0.6280 - val_accuracy: 0.6287\n",
            "Epoch 47/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.6514 - val_loss: 0.6279 - val_accuracy: 0.6287\n",
            "Epoch 48/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.6526 - val_loss: 0.6277 - val_accuracy: 0.6337\n",
            "Epoch 49/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.6526 - val_loss: 0.6280 - val_accuracy: 0.6337\n",
            "Epoch 50/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.6514 - val_loss: 0.6278 - val_accuracy: 0.6287\n",
            "Epoch 51/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6526 - val_loss: 0.6273 - val_accuracy: 0.6287\n",
            "Epoch 52/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.6489 - val_loss: 0.6276 - val_accuracy: 0.6337\n",
            "Epoch 53/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.6526 - val_loss: 0.6273 - val_accuracy: 0.6337\n",
            "Epoch 54/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.6538 - val_loss: 0.6271 - val_accuracy: 0.6386\n",
            "Epoch 55/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6476 - val_loss: 0.6271 - val_accuracy: 0.6337\n",
            "Epoch 56/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6489 - val_loss: 0.6269 - val_accuracy: 0.6386\n",
            "Epoch 57/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.6489 - val_loss: 0.6273 - val_accuracy: 0.6337\n",
            "Epoch 58/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.6514 - val_loss: 0.6270 - val_accuracy: 0.6386\n",
            "Epoch 59/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6514 - val_loss: 0.6270 - val_accuracy: 0.6386\n",
            "Epoch 60/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.6501 - val_loss: 0.6275 - val_accuracy: 0.6337\n",
            "Epoch 61/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.6526 - val_loss: 0.6271 - val_accuracy: 0.6386\n",
            "Epoch 62/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.6538 - val_loss: 0.6267 - val_accuracy: 0.6337\n",
            "Epoch 63/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.6526 - val_loss: 0.6264 - val_accuracy: 0.6386\n",
            "Epoch 64/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6489 - val_loss: 0.6270 - val_accuracy: 0.6337\n",
            "Epoch 65/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6514 - val_loss: 0.6263 - val_accuracy: 0.6386\n",
            "Epoch 66/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6476 - val_loss: 0.6265 - val_accuracy: 0.6337\n",
            "Epoch 67/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6514 - val_loss: 0.6265 - val_accuracy: 0.6386\n",
            "Epoch 68/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6514 - val_loss: 0.6268 - val_accuracy: 0.6386\n",
            "Epoch 69/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.6563 - val_loss: 0.6270 - val_accuracy: 0.6386\n",
            "Epoch 70/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.6563 - val_loss: 0.6271 - val_accuracy: 0.6386\n",
            "Epoch 71/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.6576 - val_loss: 0.6267 - val_accuracy: 0.6386\n",
            "Epoch 72/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6526 - val_loss: 0.6269 - val_accuracy: 0.6386\n",
            "Epoch 73/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.6588 - val_loss: 0.6262 - val_accuracy: 0.6436\n",
            "Epoch 74/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6538 - val_loss: 0.6263 - val_accuracy: 0.6386\n",
            "Epoch 75/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6563 - val_loss: 0.6266 - val_accuracy: 0.6436\n",
            "Epoch 76/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.6526 - val_loss: 0.6265 - val_accuracy: 0.6386\n",
            "Epoch 77/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6501 - val_loss: 0.6262 - val_accuracy: 0.6436\n",
            "Epoch 78/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.6526 - val_loss: 0.6265 - val_accuracy: 0.6386\n",
            "Epoch 79/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6526 - val_loss: 0.6268 - val_accuracy: 0.6436\n",
            "Epoch 80/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6576 - val_loss: 0.6266 - val_accuracy: 0.6436\n",
            "Epoch 81/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6526 - val_loss: 0.6268 - val_accuracy: 0.6386\n",
            "Epoch 82/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6526 - val_loss: 0.6268 - val_accuracy: 0.6386\n",
            "Epoch 83/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6514 - val_loss: 0.6270 - val_accuracy: 0.6386\n",
            "Epoch 84/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6501 - val_loss: 0.6264 - val_accuracy: 0.6436\n",
            "Epoch 85/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6501 - val_loss: 0.6267 - val_accuracy: 0.6386\n",
            "Epoch 86/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6538 - val_loss: 0.6264 - val_accuracy: 0.6436\n",
            "Epoch 87/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6576 - val_loss: 0.6273 - val_accuracy: 0.6436\n",
            "Epoch 88/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.6464 - val_loss: 0.6270 - val_accuracy: 0.6337\n",
            "Epoch 89/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6538 - val_loss: 0.6262 - val_accuracy: 0.6436\n",
            "Epoch 90/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6526 - val_loss: 0.6265 - val_accuracy: 0.6386\n",
            "Epoch 91/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.6576 - val_loss: 0.6260 - val_accuracy: 0.6436\n",
            "Epoch 92/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6514 - val_loss: 0.6263 - val_accuracy: 0.6436\n",
            "Epoch 93/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.6551 - val_loss: 0.6269 - val_accuracy: 0.6386\n",
            "Epoch 94/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6439 - val_loss: 0.6266 - val_accuracy: 0.6436\n",
            "Epoch 95/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6464 - val_loss: 0.6266 - val_accuracy: 0.6436\n",
            "Epoch 96/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6538 - val_loss: 0.6267 - val_accuracy: 0.6436\n",
            "Epoch 97/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6576 - val_loss: 0.6265 - val_accuracy: 0.6436\n",
            "Epoch 98/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6576 - val_loss: 0.6264 - val_accuracy: 0.6436\n",
            "Epoch 99/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.6563 - val_loss: 0.6265 - val_accuracy: 0.6436\n",
            "Epoch 100/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6576 - val_loss: 0.6269 - val_accuracy: 0.6436\n",
            "Epoch 101/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.6538 - val_loss: 0.6269 - val_accuracy: 0.6436\n",
            "Epoch 102/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6576 - val_loss: 0.6267 - val_accuracy: 0.6436\n",
            "Epoch 103/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6576 - val_loss: 0.6263 - val_accuracy: 0.6436\n",
            "Epoch 104/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.6576 - val_loss: 0.6270 - val_accuracy: 0.6436\n",
            "Epoch 105/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.6538 - val_loss: 0.6270 - val_accuracy: 0.6436\n",
            "Epoch 106/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.6538 - val_loss: 0.6273 - val_accuracy: 0.6436\n",
            "Epoch 107/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6588 - val_loss: 0.6269 - val_accuracy: 0.6436\n",
            "Epoch 108/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6514 - val_loss: 0.6269 - val_accuracy: 0.6436\n",
            "Epoch 109/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6563 - val_loss: 0.6272 - val_accuracy: 0.6436\n",
            "Epoch 110/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6563 - val_loss: 0.6261 - val_accuracy: 0.6436\n",
            "Epoch 111/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6613 - val_loss: 0.6266 - val_accuracy: 0.6436\n",
            "Epoch 112/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6613 - val_loss: 0.6264 - val_accuracy: 0.6436\n",
            "Epoch 113/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6600 - val_loss: 0.6268 - val_accuracy: 0.6436\n",
            "Epoch 114/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6576 - val_loss: 0.6262 - val_accuracy: 0.6436\n",
            "Epoch 115/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6576 - val_loss: 0.6268 - val_accuracy: 0.6436\n",
            "Epoch 116/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6600 - val_loss: 0.6264 - val_accuracy: 0.6436\n",
            "Epoch 117/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6600 - val_loss: 0.6266 - val_accuracy: 0.6436\n",
            "Epoch 118/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6551 - val_loss: 0.6267 - val_accuracy: 0.6436\n",
            "Epoch 119/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6600 - val_loss: 0.6262 - val_accuracy: 0.6436\n",
            "Epoch 120/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6600 - val_loss: 0.6267 - val_accuracy: 0.6436\n",
            "Epoch 121/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.6563 - val_loss: 0.6270 - val_accuracy: 0.6436\n",
            "Epoch 122/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6563 - val_loss: 0.6268 - val_accuracy: 0.6436\n",
            "Epoch 123/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6576 - val_loss: 0.6265 - val_accuracy: 0.6436\n",
            "Epoch 124/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6588 - val_loss: 0.6271 - val_accuracy: 0.6436\n",
            "Epoch 125/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6526 - val_loss: 0.6267 - val_accuracy: 0.6436\n",
            "Epoch 126/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6600 - val_loss: 0.6265 - val_accuracy: 0.6436\n",
            "Epoch 127/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6600 - val_loss: 0.6267 - val_accuracy: 0.6436\n",
            "Epoch 128/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.6563 - val_loss: 0.6266 - val_accuracy: 0.6436\n",
            "Epoch 129/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6588 - val_loss: 0.6271 - val_accuracy: 0.6436\n",
            "Epoch 130/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6600 - val_loss: 0.6274 - val_accuracy: 0.6436\n",
            "Epoch 131/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6600 - val_loss: 0.6273 - val_accuracy: 0.6436\n",
            "Epoch 132/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.6600 - val_loss: 0.6277 - val_accuracy: 0.6436\n",
            "Epoch 133/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.6526 - val_loss: 0.6278 - val_accuracy: 0.6436\n",
            "Epoch 134/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6600 - val_loss: 0.6283 - val_accuracy: 0.6436\n",
            "Epoch 135/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.6600 - val_loss: 0.6287 - val_accuracy: 0.6436\n",
            "Epoch 136/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6600 - val_loss: 0.6283 - val_accuracy: 0.6436\n",
            "Epoch 137/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6600 - val_loss: 0.6281 - val_accuracy: 0.6436\n",
            "Epoch 138/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6625 - val_loss: 0.6279 - val_accuracy: 0.6436\n",
            "Epoch 139/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.6551 - val_loss: 0.6283 - val_accuracy: 0.6436\n",
            "Epoch 140/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6600 - val_loss: 0.6285 - val_accuracy: 0.6436\n",
            "Epoch 141/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6576 - val_loss: 0.6282 - val_accuracy: 0.6436\n",
            "Epoch 142/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.6588 - val_loss: 0.6289 - val_accuracy: 0.6436\n",
            "Epoch 143/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.6600 - val_loss: 0.6281 - val_accuracy: 0.6436\n",
            "Epoch 144/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.6600 - val_loss: 0.6285 - val_accuracy: 0.6436\n",
            "Epoch 145/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6600 - val_loss: 0.6280 - val_accuracy: 0.6436\n",
            "Epoch 146/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6600 - val_loss: 0.6278 - val_accuracy: 0.6436\n",
            "Epoch 147/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6600 - val_loss: 0.6277 - val_accuracy: 0.6436\n",
            "Epoch 148/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6551 - val_loss: 0.6284 - val_accuracy: 0.6436\n",
            "Epoch 149/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6576 - val_loss: 0.6284 - val_accuracy: 0.6436\n",
            "Epoch 150/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6514 - val_loss: 0.6287 - val_accuracy: 0.6436\n",
            "Epoch 151/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6563 - val_loss: 0.6283 - val_accuracy: 0.6436\n",
            "Epoch 152/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6600 - val_loss: 0.6280 - val_accuracy: 0.6436\n",
            "Epoch 153/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6600 - val_loss: 0.6284 - val_accuracy: 0.6436\n",
            "Epoch 154/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6600 - val_loss: 0.6285 - val_accuracy: 0.6436\n",
            "Epoch 155/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6600 - val_loss: 0.6282 - val_accuracy: 0.6436\n",
            "Epoch 156/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6600 - val_loss: 0.6283 - val_accuracy: 0.6436\n",
            "Epoch 157/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6600 - val_loss: 0.6279 - val_accuracy: 0.6436\n",
            "Epoch 158/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.6600 - val_loss: 0.6279 - val_accuracy: 0.6436\n",
            "Epoch 159/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6576 - val_loss: 0.6280 - val_accuracy: 0.6436\n",
            "Epoch 160/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6600 - val_loss: 0.6282 - val_accuracy: 0.6436\n",
            "Epoch 161/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6600 - val_loss: 0.6284 - val_accuracy: 0.6436\n",
            "Epoch 162/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6600 - val_loss: 0.6284 - val_accuracy: 0.6436\n",
            "Epoch 163/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6600 - val_loss: 0.6286 - val_accuracy: 0.6436\n",
            "Epoch 164/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6259 - accuracy: 0.6600 - val_loss: 0.6286 - val_accuracy: 0.6436\n",
            "Epoch 165/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6576 - val_loss: 0.6285 - val_accuracy: 0.6436\n",
            "Epoch 166/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6600 - val_loss: 0.6281 - val_accuracy: 0.6436\n",
            "Epoch 167/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6600 - val_loss: 0.6289 - val_accuracy: 0.6436\n",
            "Epoch 168/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6600 - val_loss: 0.6288 - val_accuracy: 0.6436\n",
            "Epoch 169/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6600 - val_loss: 0.6282 - val_accuracy: 0.6436\n",
            "Epoch 170/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.6600 - val_loss: 0.6282 - val_accuracy: 0.6436\n",
            "Epoch 171/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6600 - val_loss: 0.6282 - val_accuracy: 0.6436\n",
            "Epoch 172/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6600 - val_loss: 0.6289 - val_accuracy: 0.6436\n",
            "Epoch 173/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6600 - val_loss: 0.6292 - val_accuracy: 0.6436\n",
            "Epoch 174/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6600 - val_loss: 0.6294 - val_accuracy: 0.6436\n",
            "Epoch 175/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6600 - val_loss: 0.6287 - val_accuracy: 0.6436\n",
            "Epoch 176/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6600 - val_loss: 0.6287 - val_accuracy: 0.6436\n",
            "Epoch 177/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6600 - val_loss: 0.6286 - val_accuracy: 0.6436\n",
            "Epoch 178/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6600 - val_loss: 0.6290 - val_accuracy: 0.6436\n",
            "Epoch 179/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6600 - val_loss: 0.6293 - val_accuracy: 0.6436\n",
            "Epoch 180/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6600 - val_loss: 0.6297 - val_accuracy: 0.6436\n",
            "Epoch 181/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6600 - val_loss: 0.6292 - val_accuracy: 0.6436\n",
            "Epoch 182/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6600 - val_loss: 0.6288 - val_accuracy: 0.6436\n",
            "Epoch 183/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6600 - val_loss: 0.6286 - val_accuracy: 0.6436\n",
            "Epoch 184/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6600 - val_loss: 0.6289 - val_accuracy: 0.6436\n",
            "Epoch 185/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6600 - val_loss: 0.6292 - val_accuracy: 0.6436\n",
            "Epoch 186/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6600 - val_loss: 0.6283 - val_accuracy: 0.6436\n",
            "Epoch 187/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6600 - val_loss: 0.6289 - val_accuracy: 0.6436\n",
            "Epoch 188/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6600 - val_loss: 0.6286 - val_accuracy: 0.6436\n",
            "Epoch 189/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6600 - val_loss: 0.6287 - val_accuracy: 0.6436\n",
            "Epoch 190/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6600 - val_loss: 0.6283 - val_accuracy: 0.6436\n",
            "Epoch 191/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6600 - val_loss: 0.6288 - val_accuracy: 0.6436\n",
            "Epoch 192/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6613 - val_loss: 0.6291 - val_accuracy: 0.6436\n",
            "Epoch 193/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.6600 - val_loss: 0.6291 - val_accuracy: 0.6436\n",
            "Epoch 194/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6600 - val_loss: 0.6299 - val_accuracy: 0.6436\n",
            "Epoch 195/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6600 - val_loss: 0.6294 - val_accuracy: 0.6436\n",
            "Epoch 196/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6600 - val_loss: 0.6289 - val_accuracy: 0.6436\n",
            "Epoch 197/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6600 - val_loss: 0.6283 - val_accuracy: 0.6436\n",
            "Epoch 198/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.6600 - val_loss: 0.6281 - val_accuracy: 0.6436\n",
            "Epoch 199/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6600 - val_loss: 0.6290 - val_accuracy: 0.6436\n",
            "Epoch 200/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6600 - val_loss: 0.6289 - val_accuracy: 0.6436\n",
            "Epoch 201/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6600 - val_loss: 0.6284 - val_accuracy: 0.6436\n",
            "Epoch 202/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6600 - val_loss: 0.6290 - val_accuracy: 0.6436\n",
            "Epoch 203/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6600 - val_loss: 0.6283 - val_accuracy: 0.6436\n",
            "Epoch 204/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6600 - val_loss: 0.6286 - val_accuracy: 0.6436\n",
            "Epoch 205/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6600 - val_loss: 0.6286 - val_accuracy: 0.6436\n",
            "Epoch 206/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6600 - val_loss: 0.6288 - val_accuracy: 0.6436\n",
            "Epoch 207/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6600 - val_loss: 0.6283 - val_accuracy: 0.6436\n",
            "Epoch 208/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6600 - val_loss: 0.6291 - val_accuracy: 0.6436\n",
            "Epoch 209/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6600 - val_loss: 0.6285 - val_accuracy: 0.6436\n",
            "Epoch 210/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6600 - val_loss: 0.6290 - val_accuracy: 0.6436\n",
            "Epoch 211/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6600 - val_loss: 0.6293 - val_accuracy: 0.6436\n",
            "Epoch 212/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6600 - val_loss: 0.6294 - val_accuracy: 0.6436\n",
            "Epoch 213/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6600 - val_loss: 0.6298 - val_accuracy: 0.6436\n",
            "Epoch 214/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.6600 - val_loss: 0.6297 - val_accuracy: 0.6436\n",
            "Epoch 215/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6600 - val_loss: 0.6290 - val_accuracy: 0.6436\n",
            "Epoch 216/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6600 - val_loss: 0.6291 - val_accuracy: 0.6436\n",
            "Epoch 217/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6613 - val_loss: 0.6290 - val_accuracy: 0.6436\n",
            "Epoch 218/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6600 - val_loss: 0.6301 - val_accuracy: 0.6436\n",
            "Epoch 219/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6588 - val_loss: 0.6291 - val_accuracy: 0.6436\n",
            "Epoch 220/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6600 - val_loss: 0.6292 - val_accuracy: 0.6436\n",
            "Epoch 221/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6600 - val_loss: 0.6290 - val_accuracy: 0.6436\n",
            "Epoch 222/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6600 - val_loss: 0.6290 - val_accuracy: 0.6436\n",
            "Epoch 223/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6600 - val_loss: 0.6287 - val_accuracy: 0.6436\n",
            "Epoch 224/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6600 - val_loss: 0.6287 - val_accuracy: 0.6436\n",
            "Epoch 225/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6600 - val_loss: 0.6292 - val_accuracy: 0.6436\n",
            "Epoch 226/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6600 - val_loss: 0.6292 - val_accuracy: 0.6436\n",
            "Epoch 227/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6600 - val_loss: 0.6289 - val_accuracy: 0.6436\n",
            "Epoch 228/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6600 - val_loss: 0.6289 - val_accuracy: 0.6436\n",
            "Epoch 229/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6600 - val_loss: 0.6289 - val_accuracy: 0.6436\n",
            "Epoch 230/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6600 - val_loss: 0.6288 - val_accuracy: 0.6436\n",
            "Epoch 231/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6600 - val_loss: 0.6288 - val_accuracy: 0.6436\n",
            "Epoch 232/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6600 - val_loss: 0.6288 - val_accuracy: 0.6436\n",
            "Epoch 233/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6600 - val_loss: 0.6285 - val_accuracy: 0.6436\n",
            "Epoch 234/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6613 - val_loss: 0.6288 - val_accuracy: 0.6436\n",
            "Epoch 235/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6600 - val_loss: 0.6291 - val_accuracy: 0.6436\n",
            "Epoch 236/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6625 - val_loss: 0.6291 - val_accuracy: 0.6436\n",
            "Epoch 237/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6600 - val_loss: 0.6287 - val_accuracy: 0.6436\n",
            "Epoch 238/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6588 - val_loss: 0.6291 - val_accuracy: 0.6436\n",
            "Epoch 239/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6613 - val_loss: 0.6293 - val_accuracy: 0.6436\n",
            "Epoch 240/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6600 - val_loss: 0.6297 - val_accuracy: 0.6436\n",
            "Epoch 241/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6625 - val_loss: 0.6294 - val_accuracy: 0.6436\n",
            "Epoch 242/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6625 - val_loss: 0.6297 - val_accuracy: 0.6436\n",
            "Epoch 243/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.6625 - val_loss: 0.6295 - val_accuracy: 0.6436\n",
            "Epoch 244/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6625 - val_loss: 0.6295 - val_accuracy: 0.6436\n",
            "Epoch 245/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.6625 - val_loss: 0.6300 - val_accuracy: 0.6436\n",
            "Epoch 246/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6625 - val_loss: 0.6292 - val_accuracy: 0.6436\n",
            "Epoch 247/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6625 - val_loss: 0.6298 - val_accuracy: 0.6436\n",
            "Epoch 248/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6625 - val_loss: 0.6297 - val_accuracy: 0.6436\n",
            "Epoch 249/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6625 - val_loss: 0.6294 - val_accuracy: 0.6436\n",
            "Epoch 250/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.6625 - val_loss: 0.6294 - val_accuracy: 0.6436\n",
            "Epoch 251/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6625 - val_loss: 0.6294 - val_accuracy: 0.6436\n",
            "Epoch 252/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6625 - val_loss: 0.6295 - val_accuracy: 0.6436\n",
            "Epoch 253/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6625 - val_loss: 0.6298 - val_accuracy: 0.6436\n",
            "Epoch 254/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6625 - val_loss: 0.6296 - val_accuracy: 0.6436\n",
            "Epoch 255/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6625 - val_loss: 0.6298 - val_accuracy: 0.6436\n",
            "Epoch 256/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6625 - val_loss: 0.6300 - val_accuracy: 0.6436\n",
            "Epoch 257/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6625 - val_loss: 0.6303 - val_accuracy: 0.6436\n",
            "Epoch 258/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6625 - val_loss: 0.6304 - val_accuracy: 0.6436\n",
            "Epoch 259/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6625 - val_loss: 0.6305 - val_accuracy: 0.6436\n",
            "Epoch 260/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6563 - val_loss: 0.6294 - val_accuracy: 0.6436\n",
            "Epoch 261/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6625 - val_loss: 0.6302 - val_accuracy: 0.6436\n",
            "Epoch 262/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6625 - val_loss: 0.6301 - val_accuracy: 0.6436\n",
            "Epoch 263/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6625 - val_loss: 0.6301 - val_accuracy: 0.6436\n",
            "Epoch 264/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6625 - val_loss: 0.6299 - val_accuracy: 0.6436\n",
            "Epoch 265/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6625 - val_loss: 0.6299 - val_accuracy: 0.6436\n",
            "Epoch 266/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6625 - val_loss: 0.6301 - val_accuracy: 0.6436\n",
            "Epoch 267/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6625 - val_loss: 0.6297 - val_accuracy: 0.6436\n",
            "Epoch 268/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6625 - val_loss: 0.6300 - val_accuracy: 0.6436\n",
            "Epoch 269/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6625 - val_loss: 0.6304 - val_accuracy: 0.6436\n",
            "Epoch 270/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6625 - val_loss: 0.6298 - val_accuracy: 0.6436\n",
            "Epoch 271/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6625 - val_loss: 0.6300 - val_accuracy: 0.6436\n",
            "Epoch 272/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6625 - val_loss: 0.6305 - val_accuracy: 0.6436\n",
            "Epoch 273/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6625 - val_loss: 0.6302 - val_accuracy: 0.6436\n",
            "Epoch 274/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6625 - val_loss: 0.6301 - val_accuracy: 0.6436\n",
            "Epoch 275/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6625 - val_loss: 0.6302 - val_accuracy: 0.6436\n",
            "Epoch 276/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6625 - val_loss: 0.6301 - val_accuracy: 0.6436\n",
            "Epoch 277/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6625 - val_loss: 0.6300 - val_accuracy: 0.6436\n",
            "Epoch 278/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6625 - val_loss: 0.6309 - val_accuracy: 0.6436\n",
            "Epoch 279/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.6625 - val_loss: 0.6313 - val_accuracy: 0.6436\n",
            "Epoch 280/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6625 - val_loss: 0.6309 - val_accuracy: 0.6436\n",
            "Epoch 281/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6625 - val_loss: 0.6313 - val_accuracy: 0.6436\n",
            "Epoch 282/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6625 - val_loss: 0.6306 - val_accuracy: 0.6436\n",
            "Epoch 283/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6625 - val_loss: 0.6307 - val_accuracy: 0.6436\n",
            "Epoch 284/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6625 - val_loss: 0.6302 - val_accuracy: 0.6436\n",
            "Epoch 285/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6625 - val_loss: 0.6303 - val_accuracy: 0.6436\n",
            "Epoch 286/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.6625 - val_loss: 0.6303 - val_accuracy: 0.6436\n",
            "Epoch 287/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6625 - val_loss: 0.6309 - val_accuracy: 0.6436\n",
            "Epoch 288/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6625 - val_loss: 0.6307 - val_accuracy: 0.6436\n",
            "Epoch 289/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6234 - accuracy: 0.6625 - val_loss: 0.6303 - val_accuracy: 0.6436\n",
            "Epoch 290/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6625 - val_loss: 0.6303 - val_accuracy: 0.6436\n",
            "Epoch 291/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.6625 - val_loss: 0.6299 - val_accuracy: 0.6436\n",
            "Epoch 292/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6625 - val_loss: 0.6302 - val_accuracy: 0.6436\n",
            "Epoch 293/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6625 - val_loss: 0.6301 - val_accuracy: 0.6436\n",
            "Epoch 294/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6625 - val_loss: 0.6312 - val_accuracy: 0.6436\n",
            "Epoch 295/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6625 - val_loss: 0.6311 - val_accuracy: 0.6436\n",
            "Epoch 296/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6625 - val_loss: 0.6316 - val_accuracy: 0.6436\n",
            "Epoch 297/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6625 - val_loss: 0.6311 - val_accuracy: 0.6436\n",
            "Epoch 298/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6625 - val_loss: 0.6306 - val_accuracy: 0.6436\n",
            "Epoch 299/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.6625 - val_loss: 0.6301 - val_accuracy: 0.6436\n",
            "Epoch 300/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6625 - val_loss: 0.6300 - val_accuracy: 0.6436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Kzm4Ryip6-r6",
        "outputId": "a8b9a491-dbce-41a9-fcb3-f94d48a8401f"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.xlabel('Epochs')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G-7nila6rEI",
        "outputId": "ce7215d1-9fe5-4b09-f6af-32712f78d8f6"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('test loss, test acc:', score)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test loss, test acc: [0.6299867630004883, 0.6435643434524536]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "SqIHyphS9MG_",
        "outputId": "c639256e-7625-4cec-f56a-3eea3c2445a4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n",
        "probs = model.predict_proba(x_test)\r\n",
        "# keep probabilities for the positive outcome only\r\n",
        "probs = probs[:]\r\n",
        "\r\n",
        "# calculate roc curves\r\n",
        "FPR, TPR, _ = roc_curve(y_test, probs)\r\n",
        "# plot the roc curve for the model\r\n",
        "pyplot.plot(FPR, TPR)\r\n",
        "# axis labels\r\n",
        "pyplot.xlabel('False Positive Rate')\r\n",
        "pyplot.ylabel('True Positive Rate')\r\n",
        "# show the plot\r\n",
        "pyplot.show()\r\n",
        "\r\n",
        "# calculate scores\r\n",
        "auc = roc_auc_score(y_test, probs)\r\n",
        "print('ROC AUC=%.3f' % (auc))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "ROC AUC=0.696\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}