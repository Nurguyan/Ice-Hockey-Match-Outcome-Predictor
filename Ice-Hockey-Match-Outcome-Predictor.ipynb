{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ice-Hockey-Match-Outcome-Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nurguyan/Ice-Hockey-Match-Outcome-Predictor/blob/main/Ice-Hockey-Match-Outcome-Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my16SM3edrwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9319c9a-50cc-4f27-8409-bc5db661568f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Nurguyan/Ice-Hockey-Match-Outcome-Predictor/main/data/data.csv'\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "print(df[:2])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         Date Location Team   GF   GA  ...    Sh%    Sv%    PP%    PK%  Class\n",
            "0  07/09/2018     Home  LON  247  161  ...  36.85  29.08  26.17  82.06   Loss\n",
            "1  07/09/2018     Away  TER  223  144  ...  40.69  32.31  32.44  84.10    Win\n",
            "\n",
            "[2 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPLYrmEcFJGU",
        "outputId": "3bccc549-372e-433b-a897-07bd626b2582"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "#we don't need a date since it should not affect on matches' outcome\n",
        "df = df.drop(['Date'], axis=1)\n",
        "\n",
        "#convert categorical data into integers\n",
        "df = pd.get_dummies(df, columns=['Team'])\n",
        "df['Location'] = (df['Location'] == 'Home').astype(int)\n",
        "df['Class'] = (df['Class'] == 'Win').astype(int)\n",
        "\n",
        "print(df[:5])\n",
        "df.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Location   GF   GA   GF%  ...  Team_STJ  Team_TER  Team_VAL  Team_WIS\n",
            "0         1  247  161  5.15  ...         0         0         0         0\n",
            "1         0  223  144  4.65  ...         0         1         0         0\n",
            "2         1  202  211  4.21  ...         0         0         0         0\n",
            "3         0  200  207  4.17  ...         0         0         0         0\n",
            "4         0  207  151  4.31  ...         1         0         0         0\n",
            "\n",
            "[5 rows x 21 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1008 entries, 0 to 1007\n",
            "Data columns (total 21 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Location  1008 non-null   int64  \n",
            " 1   GF        1008 non-null   int64  \n",
            " 2   GA        1008 non-null   int64  \n",
            " 3   GF%       1008 non-null   float64\n",
            " 4   GA%       1008 non-null   float64\n",
            " 5   Sh%       1008 non-null   float64\n",
            " 6   Sv%       1008 non-null   float64\n",
            " 7   PP%       1008 non-null   float64\n",
            " 8   PK%       1008 non-null   float64\n",
            " 9   Class     1008 non-null   int64  \n",
            " 10  Team_CDS  1008 non-null   uint8  \n",
            " 11  Team_CHA  1008 non-null   uint8  \n",
            " 12  Team_GAT  1008 non-null   uint8  \n",
            " 13  Team_GRA  1008 non-null   uint8  \n",
            " 14  Team_LON  1008 non-null   uint8  \n",
            " 15  Team_MTE  1008 non-null   uint8  \n",
            " 16  Team_PRI  1008 non-null   uint8  \n",
            " 17  Team_STJ  1008 non-null   uint8  \n",
            " 18  Team_TER  1008 non-null   uint8  \n",
            " 19  Team_VAL  1008 non-null   uint8  \n",
            " 20  Team_WIS  1008 non-null   uint8  \n",
            "dtypes: float64(6), int64(4), uint8(11)\n",
            "memory usage: 89.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdBYDxJAJC2w",
        "outputId": "cec30096-2e63-47cc-9c8e-aeb8e7977e55"
      },
      "source": [
        "#normalize features\n",
        "x = df.values\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "df = pd.DataFrame(x_scaled)\n",
        "print(df[:5])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0         1         2         3         4   ...   16   17   18   19   20\n",
            "0  1.0  0.728682  0.268293  0.728625  0.266862  ...  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.542636  0.164634  0.542751  0.164223  ...  0.0  0.0  1.0  0.0  0.0\n",
            "2  1.0  0.379845  0.573171  0.379182  0.574780  ...  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.364341  0.548780  0.364312  0.548387  ...  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.418605  0.207317  0.416357  0.208211  ...  0.0  1.0  0.0  0.0  0.0\n",
            "\n",
            "[5 rows x 21 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_UgQmeu3qkk",
        "outputId": "cb983bc7-22d2-4131-d987-f8b57adc6659"
      },
      "source": [
        "df_test = df.sample(frac=0.2, random_state=1337)\n",
        "df_train = df.drop(df_test.index)\n",
        "target_df_train = df_train.pop(9)\n",
        "target_df_test = df_test.pop(9)\n",
        "\n",
        "y_train = target_df_train.to_numpy(dtype='float32')\n",
        "y_test = target_df_test.to_numpy(dtype='float32')\n",
        "x_train = df_train.iloc[:,0:].to_numpy(dtype='float32')\n",
        "x_test = df_test.iloc[:,0:].to_numpy(dtype='float32')\n",
        "\n",
        "print(\"Using %d samples for training and %d for validation\" % (len(df_train), len(df_test)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 806 samples for training and 202 for validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzrRxbYhLkgy"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Eh2kLYLyl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f362d6d5-23fb-448c-b193-219c2bf95a4c"
      },
      "source": [
        "history = model.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), epochs=300, verbose=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.6592 - accuracy: 0.5794 - val_loss: 0.6261 - val_accuracy: 0.6337\n",
            "Epoch 2/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6154 - val_loss: 0.6242 - val_accuracy: 0.6287\n",
            "Epoch 3/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6253 - val_loss: 0.6218 - val_accuracy: 0.6386\n",
            "Epoch 4/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.6439 - val_loss: 0.6220 - val_accuracy: 0.6386\n",
            "Epoch 5/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.6439 - val_loss: 0.6235 - val_accuracy: 0.6386\n",
            "Epoch 6/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.6439 - val_loss: 0.6224 - val_accuracy: 0.6386\n",
            "Epoch 7/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.6439 - val_loss: 0.6249 - val_accuracy: 0.6386\n",
            "Epoch 8/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6439 - val_loss: 0.6222 - val_accuracy: 0.6386\n",
            "Epoch 9/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6439 - val_loss: 0.6272 - val_accuracy: 0.6386\n",
            "Epoch 10/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.6439 - val_loss: 0.6248 - val_accuracy: 0.6386\n",
            "Epoch 11/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6439 - val_loss: 0.6232 - val_accuracy: 0.6386\n",
            "Epoch 12/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6340 - accuracy: 0.6439 - val_loss: 0.6227 - val_accuracy: 0.6386\n",
            "Epoch 13/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.6439 - val_loss: 0.6232 - val_accuracy: 0.6386\n",
            "Epoch 14/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6439 - val_loss: 0.6255 - val_accuracy: 0.6386\n",
            "Epoch 15/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6390 - val_loss: 0.6225 - val_accuracy: 0.6386\n",
            "Epoch 16/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6464 - val_loss: 0.6251 - val_accuracy: 0.6386\n",
            "Epoch 17/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6464 - val_loss: 0.6267 - val_accuracy: 0.6386\n",
            "Epoch 18/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6464 - val_loss: 0.6215 - val_accuracy: 0.6535\n",
            "Epoch 19/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.6464 - val_loss: 0.6257 - val_accuracy: 0.6535\n",
            "Epoch 20/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.6489 - val_loss: 0.6255 - val_accuracy: 0.6337\n",
            "Epoch 21/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6576 - val_loss: 0.6261 - val_accuracy: 0.6337\n",
            "Epoch 22/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.6576 - val_loss: 0.6250 - val_accuracy: 0.6337\n",
            "Epoch 23/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.6551 - val_loss: 0.6253 - val_accuracy: 0.6337\n",
            "Epoch 24/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6576 - val_loss: 0.6282 - val_accuracy: 0.6337\n",
            "Epoch 25/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.6576 - val_loss: 0.6286 - val_accuracy: 0.6337\n",
            "Epoch 26/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6576 - val_loss: 0.6272 - val_accuracy: 0.6535\n",
            "Epoch 27/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6551 - val_loss: 0.6272 - val_accuracy: 0.6535\n",
            "Epoch 28/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6588 - val_loss: 0.6267 - val_accuracy: 0.6535\n",
            "Epoch 29/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6600 - val_loss: 0.6266 - val_accuracy: 0.6535\n",
            "Epoch 30/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6576 - val_loss: 0.6294 - val_accuracy: 0.6337\n",
            "Epoch 31/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6576 - val_loss: 0.6278 - val_accuracy: 0.6535\n",
            "Epoch 32/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.6576 - val_loss: 0.6285 - val_accuracy: 0.6337\n",
            "Epoch 33/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6576 - val_loss: 0.6313 - val_accuracy: 0.6337\n",
            "Epoch 34/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.6576 - val_loss: 0.6285 - val_accuracy: 0.6337\n",
            "Epoch 35/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6576 - val_loss: 0.6299 - val_accuracy: 0.6337\n",
            "Epoch 36/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6538 - val_loss: 0.6286 - val_accuracy: 0.6535\n",
            "Epoch 37/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.6563 - val_loss: 0.6301 - val_accuracy: 0.6337\n",
            "Epoch 38/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6613 - val_loss: 0.6278 - val_accuracy: 0.6436\n",
            "Epoch 39/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6600 - val_loss: 0.6331 - val_accuracy: 0.6337\n",
            "Epoch 40/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.6576 - val_loss: 0.6347 - val_accuracy: 0.6337\n",
            "Epoch 41/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6576 - val_loss: 0.6304 - val_accuracy: 0.6436\n",
            "Epoch 42/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.6576 - val_loss: 0.6332 - val_accuracy: 0.6337\n",
            "Epoch 43/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.6576 - val_loss: 0.6264 - val_accuracy: 0.6436\n",
            "Epoch 44/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6576 - val_loss: 0.6312 - val_accuracy: 0.6337\n",
            "Epoch 45/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.6576 - val_loss: 0.6330 - val_accuracy: 0.6337\n",
            "Epoch 46/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.6576 - val_loss: 0.6301 - val_accuracy: 0.6337\n",
            "Epoch 47/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6576 - val_loss: 0.6266 - val_accuracy: 0.6386\n",
            "Epoch 48/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6501 - val_loss: 0.6292 - val_accuracy: 0.6337\n",
            "Epoch 49/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6538 - val_loss: 0.6278 - val_accuracy: 0.6386\n",
            "Epoch 50/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6588 - val_loss: 0.6274 - val_accuracy: 0.6386\n",
            "Epoch 51/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6588 - val_loss: 0.6289 - val_accuracy: 0.6386\n",
            "Epoch 52/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6551 - val_loss: 0.6320 - val_accuracy: 0.6287\n",
            "Epoch 53/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6576 - val_loss: 0.6300 - val_accuracy: 0.6485\n",
            "Epoch 54/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6538 - val_loss: 0.6285 - val_accuracy: 0.6485\n",
            "Epoch 55/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6563 - val_loss: 0.6293 - val_accuracy: 0.6485\n",
            "Epoch 56/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.6563 - val_loss: 0.6291 - val_accuracy: 0.6485\n",
            "Epoch 57/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6563 - val_loss: 0.6289 - val_accuracy: 0.6485\n",
            "Epoch 58/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6563 - val_loss: 0.6320 - val_accuracy: 0.6287\n",
            "Epoch 59/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6600 - val_loss: 0.6289 - val_accuracy: 0.6485\n",
            "Epoch 60/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6588 - val_loss: 0.6305 - val_accuracy: 0.6287\n",
            "Epoch 61/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6551 - val_loss: 0.6318 - val_accuracy: 0.6287\n",
            "Epoch 62/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.6501 - val_loss: 0.6321 - val_accuracy: 0.6337\n",
            "Epoch 63/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6551 - val_loss: 0.6305 - val_accuracy: 0.6485\n",
            "Epoch 64/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6563 - val_loss: 0.6313 - val_accuracy: 0.6485\n",
            "Epoch 65/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6563 - val_loss: 0.6306 - val_accuracy: 0.6485\n",
            "Epoch 66/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6588 - val_loss: 0.6300 - val_accuracy: 0.6485\n",
            "Epoch 67/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6563 - val_loss: 0.6299 - val_accuracy: 0.6386\n",
            "Epoch 68/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6526 - val_loss: 0.6317 - val_accuracy: 0.6287\n",
            "Epoch 69/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6526 - val_loss: 0.6309 - val_accuracy: 0.6287\n",
            "Epoch 70/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6563 - val_loss: 0.6301 - val_accuracy: 0.6485\n",
            "Epoch 71/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6600 - val_loss: 0.6305 - val_accuracy: 0.6485\n",
            "Epoch 72/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6538 - val_loss: 0.6316 - val_accuracy: 0.6287\n",
            "Epoch 73/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6551 - val_loss: 0.6304 - val_accuracy: 0.6485\n",
            "Epoch 74/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6563 - val_loss: 0.6303 - val_accuracy: 0.6386\n",
            "Epoch 75/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6588 - val_loss: 0.6312 - val_accuracy: 0.6485\n",
            "Epoch 76/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6514 - val_loss: 0.6303 - val_accuracy: 0.6485\n",
            "Epoch 77/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6551 - val_loss: 0.6337 - val_accuracy: 0.6287\n",
            "Epoch 78/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6576 - val_loss: 0.6340 - val_accuracy: 0.6287\n",
            "Epoch 79/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6576 - val_loss: 0.6301 - val_accuracy: 0.6386\n",
            "Epoch 80/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.6526 - val_loss: 0.6297 - val_accuracy: 0.6485\n",
            "Epoch 81/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6563 - val_loss: 0.6310 - val_accuracy: 0.6485\n",
            "Epoch 82/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.6563 - val_loss: 0.6318 - val_accuracy: 0.6485\n",
            "Epoch 83/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6563 - val_loss: 0.6302 - val_accuracy: 0.6485\n",
            "Epoch 84/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6588 - val_loss: 0.6312 - val_accuracy: 0.6386\n",
            "Epoch 85/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6538 - val_loss: 0.6321 - val_accuracy: 0.6287\n",
            "Epoch 86/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6588 - val_loss: 0.6302 - val_accuracy: 0.6386\n",
            "Epoch 87/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.6588 - val_loss: 0.6300 - val_accuracy: 0.6386\n",
            "Epoch 88/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6600 - val_loss: 0.6348 - val_accuracy: 0.6287\n",
            "Epoch 89/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6588 - val_loss: 0.6318 - val_accuracy: 0.6485\n",
            "Epoch 90/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6576 - val_loss: 0.6344 - val_accuracy: 0.6287\n",
            "Epoch 91/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6538 - val_loss: 0.6311 - val_accuracy: 0.6485\n",
            "Epoch 92/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6563 - val_loss: 0.6342 - val_accuracy: 0.6287\n",
            "Epoch 93/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6563 - val_loss: 0.6325 - val_accuracy: 0.6287\n",
            "Epoch 94/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6563 - val_loss: 0.6312 - val_accuracy: 0.6485\n",
            "Epoch 95/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6551 - val_loss: 0.6326 - val_accuracy: 0.6287\n",
            "Epoch 96/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6514 - val_loss: 0.6324 - val_accuracy: 0.6287\n",
            "Epoch 97/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6588 - val_loss: 0.6327 - val_accuracy: 0.6287\n",
            "Epoch 98/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6563 - val_loss: 0.6292 - val_accuracy: 0.6485\n",
            "Epoch 99/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6588 - val_loss: 0.6317 - val_accuracy: 0.6485\n",
            "Epoch 100/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.6538 - val_loss: 0.6349 - val_accuracy: 0.6287\n",
            "Epoch 101/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6600 - val_loss: 0.6319 - val_accuracy: 0.6485\n",
            "Epoch 102/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6563 - val_loss: 0.6306 - val_accuracy: 0.6485\n",
            "Epoch 103/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.6538 - val_loss: 0.6307 - val_accuracy: 0.6485\n",
            "Epoch 104/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6563 - val_loss: 0.6313 - val_accuracy: 0.6485\n",
            "Epoch 105/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6526 - val_loss: 0.6323 - val_accuracy: 0.6485\n",
            "Epoch 106/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.6563 - val_loss: 0.6330 - val_accuracy: 0.6485\n",
            "Epoch 107/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6563 - val_loss: 0.6315 - val_accuracy: 0.6485\n",
            "Epoch 108/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6576 - val_loss: 0.6334 - val_accuracy: 0.6287\n",
            "Epoch 109/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6538 - val_loss: 0.6335 - val_accuracy: 0.6287\n",
            "Epoch 110/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6588 - val_loss: 0.6330 - val_accuracy: 0.6485\n",
            "Epoch 111/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6563 - val_loss: 0.6308 - val_accuracy: 0.6485\n",
            "Epoch 112/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6576 - val_loss: 0.6341 - val_accuracy: 0.6287\n",
            "Epoch 113/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6588 - val_loss: 0.6317 - val_accuracy: 0.6485\n",
            "Epoch 114/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.6563 - val_loss: 0.6341 - val_accuracy: 0.6287\n",
            "Epoch 115/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6588 - val_loss: 0.6318 - val_accuracy: 0.6485\n",
            "Epoch 116/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6514 - val_loss: 0.6325 - val_accuracy: 0.6485\n",
            "Epoch 117/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6563 - val_loss: 0.6327 - val_accuracy: 0.6485\n",
            "Epoch 118/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6576 - val_loss: 0.6351 - val_accuracy: 0.6287\n",
            "Epoch 119/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.6551 - val_loss: 0.6356 - val_accuracy: 0.6485\n",
            "Epoch 120/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6563 - val_loss: 0.6345 - val_accuracy: 0.6485\n",
            "Epoch 121/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.6526 - val_loss: 0.6370 - val_accuracy: 0.6287\n",
            "Epoch 122/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6538 - val_loss: 0.6337 - val_accuracy: 0.6287\n",
            "Epoch 123/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6588 - val_loss: 0.6339 - val_accuracy: 0.6287\n",
            "Epoch 124/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6563 - val_loss: 0.6318 - val_accuracy: 0.6485\n",
            "Epoch 125/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.6563 - val_loss: 0.6323 - val_accuracy: 0.6485\n",
            "Epoch 126/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.6600 - val_loss: 0.6352 - val_accuracy: 0.6287\n",
            "Epoch 127/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6538 - val_loss: 0.6320 - val_accuracy: 0.6485\n",
            "Epoch 128/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.6576 - val_loss: 0.6328 - val_accuracy: 0.6287\n",
            "Epoch 129/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.6588 - val_loss: 0.6346 - val_accuracy: 0.6287\n",
            "Epoch 130/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.6588 - val_loss: 0.6335 - val_accuracy: 0.6485\n",
            "Epoch 131/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.6538 - val_loss: 0.6312 - val_accuracy: 0.6485\n",
            "Epoch 132/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6563 - val_loss: 0.6336 - val_accuracy: 0.6485\n",
            "Epoch 133/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.6526 - val_loss: 0.6350 - val_accuracy: 0.6287\n",
            "Epoch 134/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6563 - val_loss: 0.6319 - val_accuracy: 0.6485\n",
            "Epoch 135/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.6563 - val_loss: 0.6302 - val_accuracy: 0.6485\n",
            "Epoch 136/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.6538 - val_loss: 0.6313 - val_accuracy: 0.6485\n",
            "Epoch 137/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6563 - val_loss: 0.6328 - val_accuracy: 0.6485\n",
            "Epoch 138/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.6563 - val_loss: 0.6338 - val_accuracy: 0.6287\n",
            "Epoch 139/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.6600 - val_loss: 0.6327 - val_accuracy: 0.6485\n",
            "Epoch 140/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.6563 - val_loss: 0.6321 - val_accuracy: 0.6485\n",
            "Epoch 141/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.6588 - val_loss: 0.6358 - val_accuracy: 0.6287\n",
            "Epoch 142/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6514 - val_loss: 0.6342 - val_accuracy: 0.6485\n",
            "Epoch 143/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.6551 - val_loss: 0.6347 - val_accuracy: 0.6287\n",
            "Epoch 144/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6538 - val_loss: 0.6315 - val_accuracy: 0.6485\n",
            "Epoch 145/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6563 - val_loss: 0.6330 - val_accuracy: 0.6287\n",
            "Epoch 146/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6588 - val_loss: 0.6344 - val_accuracy: 0.6287\n",
            "Epoch 147/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6588 - val_loss: 0.6338 - val_accuracy: 0.6287\n",
            "Epoch 148/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.6588 - val_loss: 0.6308 - val_accuracy: 0.6287\n",
            "Epoch 149/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6588 - val_loss: 0.6331 - val_accuracy: 0.6287\n",
            "Epoch 150/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6588 - val_loss: 0.6337 - val_accuracy: 0.6287\n",
            "Epoch 151/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6526 - val_loss: 0.6316 - val_accuracy: 0.6287\n",
            "Epoch 152/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6588 - val_loss: 0.6322 - val_accuracy: 0.6287\n",
            "Epoch 153/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6588 - val_loss: 0.6330 - val_accuracy: 0.6287\n",
            "Epoch 154/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6588 - val_loss: 0.6351 - val_accuracy: 0.6287\n",
            "Epoch 155/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6588 - val_loss: 0.6348 - val_accuracy: 0.6287\n",
            "Epoch 156/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6588 - val_loss: 0.6330 - val_accuracy: 0.6287\n",
            "Epoch 157/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.6588 - val_loss: 0.6344 - val_accuracy: 0.6287\n",
            "Epoch 158/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.6588 - val_loss: 0.6360 - val_accuracy: 0.6287\n",
            "Epoch 159/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6551 - val_loss: 0.6324 - val_accuracy: 0.6386\n",
            "Epoch 160/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6588 - val_loss: 0.6330 - val_accuracy: 0.6287\n",
            "Epoch 161/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6588 - val_loss: 0.6345 - val_accuracy: 0.6287\n",
            "Epoch 162/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6588 - val_loss: 0.6340 - val_accuracy: 0.6287\n",
            "Epoch 163/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6588 - val_loss: 0.6336 - val_accuracy: 0.6287\n",
            "Epoch 164/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6588 - val_loss: 0.6340 - val_accuracy: 0.6287\n",
            "Epoch 165/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6588 - val_loss: 0.6335 - val_accuracy: 0.6287\n",
            "Epoch 166/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6588 - val_loss: 0.6338 - val_accuracy: 0.6287\n",
            "Epoch 167/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6588 - val_loss: 0.6333 - val_accuracy: 0.6287\n",
            "Epoch 168/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6588 - val_loss: 0.6363 - val_accuracy: 0.6287\n",
            "Epoch 169/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6588 - val_loss: 0.6349 - val_accuracy: 0.6287\n",
            "Epoch 170/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.6588 - val_loss: 0.6322 - val_accuracy: 0.6287\n",
            "Epoch 171/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6588 - val_loss: 0.6342 - val_accuracy: 0.6287\n",
            "Epoch 172/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6588 - val_loss: 0.6343 - val_accuracy: 0.6287\n",
            "Epoch 173/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6588 - val_loss: 0.6348 - val_accuracy: 0.6287\n",
            "Epoch 174/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6588 - val_loss: 0.6319 - val_accuracy: 0.6287\n",
            "Epoch 175/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6588 - val_loss: 0.6325 - val_accuracy: 0.6287\n",
            "Epoch 176/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6588 - val_loss: 0.6352 - val_accuracy: 0.6287\n",
            "Epoch 177/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6588 - val_loss: 0.6343 - val_accuracy: 0.6287\n",
            "Epoch 178/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6588 - val_loss: 0.6352 - val_accuracy: 0.6287\n",
            "Epoch 179/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6588 - val_loss: 0.6374 - val_accuracy: 0.6287\n",
            "Epoch 180/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6588 - val_loss: 0.6349 - val_accuracy: 0.6287\n",
            "Epoch 181/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.6588 - val_loss: 0.6358 - val_accuracy: 0.6287\n",
            "Epoch 182/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6588 - val_loss: 0.6351 - val_accuracy: 0.6287\n",
            "Epoch 183/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6588 - val_loss: 0.6359 - val_accuracy: 0.6287\n",
            "Epoch 184/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6588 - val_loss: 0.6347 - val_accuracy: 0.6287\n",
            "Epoch 185/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6588 - val_loss: 0.6328 - val_accuracy: 0.6287\n",
            "Epoch 186/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6563 - val_loss: 0.6340 - val_accuracy: 0.6386\n",
            "Epoch 187/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6514 - val_loss: 0.6341 - val_accuracy: 0.6287\n",
            "Epoch 188/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6588 - val_loss: 0.6370 - val_accuracy: 0.6287\n",
            "Epoch 189/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6600 - val_loss: 0.6341 - val_accuracy: 0.6386\n",
            "Epoch 190/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6576 - val_loss: 0.6361 - val_accuracy: 0.6287\n",
            "Epoch 191/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6576 - val_loss: 0.6351 - val_accuracy: 0.6287\n",
            "Epoch 192/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6588 - val_loss: 0.6346 - val_accuracy: 0.6287\n",
            "Epoch 193/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6588 - val_loss: 0.6348 - val_accuracy: 0.6287\n",
            "Epoch 194/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6588 - val_loss: 0.6348 - val_accuracy: 0.6287\n",
            "Epoch 195/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.6588 - val_loss: 0.6365 - val_accuracy: 0.6287\n",
            "Epoch 196/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6576 - val_loss: 0.6338 - val_accuracy: 0.6287\n",
            "Epoch 197/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6563 - val_loss: 0.6343 - val_accuracy: 0.6386\n",
            "Epoch 198/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.6563 - val_loss: 0.6332 - val_accuracy: 0.6287\n",
            "Epoch 199/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6588 - val_loss: 0.6345 - val_accuracy: 0.6287\n",
            "Epoch 200/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6600 - val_loss: 0.6323 - val_accuracy: 0.6386\n",
            "Epoch 201/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6576 - val_loss: 0.6343 - val_accuracy: 0.6287\n",
            "Epoch 202/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6588 - val_loss: 0.6358 - val_accuracy: 0.6287\n",
            "Epoch 203/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6600 - val_loss: 0.6324 - val_accuracy: 0.6386\n",
            "Epoch 204/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6563 - val_loss: 0.6344 - val_accuracy: 0.6287\n",
            "Epoch 205/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6600 - val_loss: 0.6347 - val_accuracy: 0.6287\n",
            "Epoch 206/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6538 - val_loss: 0.6363 - val_accuracy: 0.6287\n",
            "Epoch 207/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6588 - val_loss: 0.6342 - val_accuracy: 0.6287\n",
            "Epoch 208/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6588 - val_loss: 0.6362 - val_accuracy: 0.6287\n",
            "Epoch 209/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.6588 - val_loss: 0.6352 - val_accuracy: 0.6287\n",
            "Epoch 210/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.6588 - val_loss: 0.6380 - val_accuracy: 0.6287\n",
            "Epoch 211/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.6588 - val_loss: 0.6384 - val_accuracy: 0.6287\n",
            "Epoch 212/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.6588 - val_loss: 0.6373 - val_accuracy: 0.6287\n",
            "Epoch 213/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6613 - val_loss: 0.6347 - val_accuracy: 0.6287\n",
            "Epoch 214/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6188 - accuracy: 0.6588 - val_loss: 0.6371 - val_accuracy: 0.6287\n",
            "Epoch 215/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6588 - val_loss: 0.6350 - val_accuracy: 0.6287\n",
            "Epoch 216/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6588 - val_loss: 0.6347 - val_accuracy: 0.6287\n",
            "Epoch 217/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.6588 - val_loss: 0.6347 - val_accuracy: 0.6287\n",
            "Epoch 218/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6182 - accuracy: 0.6588 - val_loss: 0.6363 - val_accuracy: 0.6287\n",
            "Epoch 219/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6588 - val_loss: 0.6364 - val_accuracy: 0.6287\n",
            "Epoch 220/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.6588 - val_loss: 0.6344 - val_accuracy: 0.6386\n",
            "Epoch 221/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6613 - val_loss: 0.6366 - val_accuracy: 0.6287\n",
            "Epoch 222/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6526 - val_loss: 0.6370 - val_accuracy: 0.6386\n",
            "Epoch 223/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6588 - val_loss: 0.6352 - val_accuracy: 0.6386\n",
            "Epoch 224/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6538 - val_loss: 0.6377 - val_accuracy: 0.6287\n",
            "Epoch 225/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6588 - val_loss: 0.6354 - val_accuracy: 0.6386\n",
            "Epoch 226/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6588 - val_loss: 0.6358 - val_accuracy: 0.6386\n",
            "Epoch 227/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6588 - val_loss: 0.6369 - val_accuracy: 0.6287\n",
            "Epoch 228/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6588 - val_loss: 0.6371 - val_accuracy: 0.6287\n",
            "Epoch 229/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6588 - val_loss: 0.6342 - val_accuracy: 0.6386\n",
            "Epoch 230/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6625 - val_loss: 0.6366 - val_accuracy: 0.6287\n",
            "Epoch 231/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6576 - val_loss: 0.6362 - val_accuracy: 0.6386\n",
            "Epoch 232/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6613 - val_loss: 0.6365 - val_accuracy: 0.6386\n",
            "Epoch 233/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6551 - val_loss: 0.6352 - val_accuracy: 0.6287\n",
            "Epoch 234/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6588 - val_loss: 0.6345 - val_accuracy: 0.6287\n",
            "Epoch 235/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6588 - val_loss: 0.6360 - val_accuracy: 0.6287\n",
            "Epoch 236/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6588 - val_loss: 0.6366 - val_accuracy: 0.6287\n",
            "Epoch 237/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6588 - val_loss: 0.6369 - val_accuracy: 0.6287\n",
            "Epoch 238/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6551 - val_loss: 0.6366 - val_accuracy: 0.6287\n",
            "Epoch 239/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6588 - val_loss: 0.6377 - val_accuracy: 0.6287\n",
            "Epoch 240/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.6538 - val_loss: 0.6378 - val_accuracy: 0.6287\n",
            "Epoch 241/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6588 - val_loss: 0.6388 - val_accuracy: 0.6287\n",
            "Epoch 242/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6588 - val_loss: 0.6367 - val_accuracy: 0.6287\n",
            "Epoch 243/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6588 - val_loss: 0.6373 - val_accuracy: 0.6287\n",
            "Epoch 244/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6588 - val_loss: 0.6364 - val_accuracy: 0.6287\n",
            "Epoch 245/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6588 - val_loss: 0.6377 - val_accuracy: 0.6287\n",
            "Epoch 246/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6588 - val_loss: 0.6388 - val_accuracy: 0.6287\n",
            "Epoch 247/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6576 - val_loss: 0.6384 - val_accuracy: 0.6287\n",
            "Epoch 248/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6182 - accuracy: 0.6588 - val_loss: 0.6379 - val_accuracy: 0.6287\n",
            "Epoch 249/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6588 - val_loss: 0.6377 - val_accuracy: 0.6287\n",
            "Epoch 250/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6588 - val_loss: 0.6378 - val_accuracy: 0.6287\n",
            "Epoch 251/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6576 - val_loss: 0.6386 - val_accuracy: 0.6287\n",
            "Epoch 252/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6551 - val_loss: 0.6389 - val_accuracy: 0.6287\n",
            "Epoch 253/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6588 - val_loss: 0.6381 - val_accuracy: 0.6287\n",
            "Epoch 254/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6588 - val_loss: 0.6383 - val_accuracy: 0.6287\n",
            "Epoch 255/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6588 - val_loss: 0.6370 - val_accuracy: 0.6287\n",
            "Epoch 256/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6588 - val_loss: 0.6392 - val_accuracy: 0.6287\n",
            "Epoch 257/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6588 - val_loss: 0.6387 - val_accuracy: 0.6287\n",
            "Epoch 258/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6588 - val_loss: 0.6354 - val_accuracy: 0.6287\n",
            "Epoch 259/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6588 - val_loss: 0.6372 - val_accuracy: 0.6287\n",
            "Epoch 260/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6588 - val_loss: 0.6377 - val_accuracy: 0.6287\n",
            "Epoch 261/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6588 - val_loss: 0.6375 - val_accuracy: 0.6287\n",
            "Epoch 262/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6588 - val_loss: 0.6392 - val_accuracy: 0.6287\n",
            "Epoch 263/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6588 - val_loss: 0.6378 - val_accuracy: 0.6287\n",
            "Epoch 264/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6182 - accuracy: 0.6563 - val_loss: 0.6381 - val_accuracy: 0.6287\n",
            "Epoch 265/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6588 - val_loss: 0.6365 - val_accuracy: 0.6287\n",
            "Epoch 266/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6588 - val_loss: 0.6401 - val_accuracy: 0.6287\n",
            "Epoch 267/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6588 - val_loss: 0.6380 - val_accuracy: 0.6287\n",
            "Epoch 268/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6576 - val_loss: 0.6365 - val_accuracy: 0.6386\n",
            "Epoch 269/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6588 - val_loss: 0.6399 - val_accuracy: 0.6287\n",
            "Epoch 270/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6588 - val_loss: 0.6392 - val_accuracy: 0.6287\n",
            "Epoch 271/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6588 - val_loss: 0.6383 - val_accuracy: 0.6287\n",
            "Epoch 272/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6588 - val_loss: 0.6377 - val_accuracy: 0.6287\n",
            "Epoch 273/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6600 - val_loss: 0.6382 - val_accuracy: 0.6386\n",
            "Epoch 274/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6576 - val_loss: 0.6373 - val_accuracy: 0.6386\n",
            "Epoch 275/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6576 - val_loss: 0.6375 - val_accuracy: 0.6287\n",
            "Epoch 276/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6551 - val_loss: 0.6384 - val_accuracy: 0.6287\n",
            "Epoch 277/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6563 - val_loss: 0.6382 - val_accuracy: 0.6386\n",
            "Epoch 278/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6588 - val_loss: 0.6424 - val_accuracy: 0.6188\n",
            "Epoch 279/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6576 - val_loss: 0.6398 - val_accuracy: 0.6287\n",
            "Epoch 280/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6576 - val_loss: 0.6423 - val_accuracy: 0.6188\n",
            "Epoch 281/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6600 - val_loss: 0.6405 - val_accuracy: 0.6287\n",
            "Epoch 282/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6588 - val_loss: 0.6395 - val_accuracy: 0.6287\n",
            "Epoch 283/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.6588 - val_loss: 0.6402 - val_accuracy: 0.6287\n",
            "Epoch 284/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6526 - val_loss: 0.6387 - val_accuracy: 0.6386\n",
            "Epoch 285/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6538 - val_loss: 0.6381 - val_accuracy: 0.6386\n",
            "Epoch 286/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6588 - val_loss: 0.6410 - val_accuracy: 0.6287\n",
            "Epoch 287/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.6538 - val_loss: 0.6386 - val_accuracy: 0.6386\n",
            "Epoch 288/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6588 - val_loss: 0.6410 - val_accuracy: 0.6287\n",
            "Epoch 289/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6588 - val_loss: 0.6415 - val_accuracy: 0.6287\n",
            "Epoch 290/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6551 - val_loss: 0.6380 - val_accuracy: 0.6485\n",
            "Epoch 291/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6563 - val_loss: 0.6386 - val_accuracy: 0.6485\n",
            "Epoch 292/300\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.6600 - val_loss: 0.6397 - val_accuracy: 0.6386\n",
            "Epoch 293/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6576 - val_loss: 0.6411 - val_accuracy: 0.6287\n",
            "Epoch 294/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6588 - val_loss: 0.6404 - val_accuracy: 0.6287\n",
            "Epoch 295/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6563 - val_loss: 0.6392 - val_accuracy: 0.6386\n",
            "Epoch 296/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6576 - val_loss: 0.6373 - val_accuracy: 0.6485\n",
            "Epoch 297/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6600 - val_loss: 0.6375 - val_accuracy: 0.6386\n",
            "Epoch 298/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6588 - val_loss: 0.6394 - val_accuracy: 0.6386\n",
            "Epoch 299/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6613 - val_loss: 0.6408 - val_accuracy: 0.6287\n",
            "Epoch 300/300\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6538 - val_loss: 0.6407 - val_accuracy: 0.6287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Kzm4Ryip6-r6",
        "outputId": "07f69dca-ece4-4f14-b4a1-bbec9e5b00cd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.xlabel('Epochs')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epochs')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G-7nila6rEI",
        "outputId": "35335dfe-4f97-45e3-de3b-5e58809abe6c"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('test loss, test acc:', score)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test loss, test acc: [0.640684962272644, 0.6287128925323486]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}